{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "510b7d52",
      "metadata": {
        "id": "510b7d52"
      },
      "source": [
        "# Thermal Neural Networks (Pytorch example)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b698f89e",
      "metadata": {
        "id": "b698f89e"
      },
      "source": [
        "This jupyter notebook showcases how to utilize a thermal neural network (TNN) on an exemplary data set.\n",
        "This example is more concise than the TF2 example and standalone (not utilizing the \"tf2utils\" package) but lacks a few convenient mechanics in turn (e.g., validation set, early stopping, plotting helpers etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d500214",
      "metadata": {
        "id": "6d500214"
      },
      "source": [
        "The data set can be downloaded from [Kaggle](https://www.kaggle.com/wkirgsn/electric-motor-temperature).\n",
        "It should be placed in `data/input/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c6d96117",
      "metadata": {
        "id": "c6d96117"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import Parameter as TorchParam\n",
        "from torch import Tensor\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01ef7289",
      "metadata": {
        "id": "01ef7289"
      },
      "source": [
        "## Data setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c53203e5",
      "metadata": {
        "id": "c53203e5"
      },
      "outputs": [],
      "source": [
        "path_to_csv = Path().cwd() / \"data\" / \"input\" / \"measures_v2.csv\"\n",
        "data = pd.read_csv(path_to_csv)\n",
        "target_cols = [\"pm\", \"stator_yoke\", \"stator_tooth\", \"stator_winding\"]\n",
        "\n",
        "temperature_cols = target_cols + [\"ambient\", \"coolant\"]\n",
        "test_profiles = [60, 62, 74]\n",
        "train_profiles = [p for p in data.profile_id.unique() if p not in test_profiles]\n",
        "profile_sizes = data.groupby(\"profile_id\").agg(\"size\")\n",
        "\n",
        "# normalize\n",
        "non_temperature_cols = [c for c in data if c not in temperature_cols + [\"profile_id\"]]\n",
        "data.loc[:, temperature_cols] /= 200  # deg C\n",
        "data.loc[:, non_temperature_cols] /= data.loc[:, non_temperature_cols].abs().max(axis=0)\n",
        "\n",
        "# extra feats (FE)\n",
        "if {\"i_d\", \"i_q\", \"u_d\", \"u_q\"}.issubset(set(data.columns.tolist())):\n",
        "    extra_feats = {\n",
        "        \"i_s\": lambda x: np.sqrt((x[\"i_d\"] ** 2 + x[\"i_q\"] ** 2)),\n",
        "        \"u_s\": lambda x: np.sqrt((x[\"u_d\"] ** 2 + x[\"u_q\"] ** 2)),\n",
        "    }\n",
        "data = data.assign(**extra_feats)\n",
        "input_cols = [c for c in data.columns if c not in target_cols]\n",
        "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "# overwrite. We recommend CPU over GPU here, as that runs faster with pytorch on this data set\n",
        "device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s2nErDfOGlE6"
      },
      "id": "s2nErDfOGlE6",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fe40138e",
      "metadata": {
        "id": "fe40138e",
        "outputId": "ef5f0dac-a917-4e49-dde3-9da1c27c87d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'[nan] not in index'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1c8f4531664f>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtrain_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_profiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mtest_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_profiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-1c8f4531664f>\u001b[0m in \u001b[0;36mgenerate_tensor\u001b[0;34m(profiles_list)\u001b[0m\n\u001b[1;32m     14\u001b[0m     in the cost function (i.e., it acts as masking tensor)\"\"\"\n\u001b[1;32m     15\u001b[0m     tensor = np.full(\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mprofile_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprofiles_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiles_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_rows_with_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;31m# handle the dup indexing case GH#4246\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1418\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1362\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1558\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '[nan] not in index'"
          ]
        }
      ],
      "source": [
        "# Rearrange features\n",
        "input_cols = [c for c in data.columns if c not in target_cols + [\"profile_id\"]]\n",
        "data = data.loc[:, input_cols + [\"profile_id\"] + target_cols]\n",
        "\n",
        "\n",
        "def generate_tensor(profiles_list):\n",
        "    \"\"\"Returns profiles of the data set in a coherent 3D tensor with\n",
        "    time-major shape (T, B, F) where\n",
        "    T : Maximum profile length\n",
        "    B : Batch size = Amount of profiles\n",
        "    F : Amount of input features.\n",
        "\n",
        "    Also returns a likewise-shaped sample_weights tensor, which zeros out post-padded zeros for use\n",
        "    in the cost function (i.e., it acts as masking tensor)\"\"\"\n",
        "    tensor = np.full(\n",
        "        (profile_sizes[profiles_list].max(), len(profiles_list), data.shape[1] - 1),\n",
        "        np.nan,\n",
        "    )\n",
        "    for i, (pid, df) in enumerate(\n",
        "        data.loc[data.profile_id.isin(profiles_list), :].groupby(\"profile_id\")\n",
        "    ):\n",
        "        assert pid in profiles_list, f\"PID is not in {profiles_list}!\"\n",
        "        tensor[: len(df), i, :] = df.drop(columns=\"profile_id\").to_numpy()\n",
        "    sample_weights = 1 - np.isnan(tensor[:, :, 0])\n",
        "    tensor = np.nan_to_num(tensor).astype(np.float32)\n",
        "    tensor = torch.from_numpy(tensor).to(device)\n",
        "    sample_weights = torch.from_numpy(sample_weights).to(device)\n",
        "    return tensor, sample_weights\n",
        "\n",
        "\n",
        "train_tensor, train_sample_weights = generate_tensor(train_profiles)\n",
        "test_tensor, test_sample_weights = generate_tensor(test_profiles)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1db87e5c",
      "metadata": {
        "id": "1db87e5c"
      },
      "source": [
        "## Model declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e0e8b21",
      "metadata": {
        "metadata": {},
        "id": "1e0e8b21"
      },
      "outputs": [],
      "source": [
        "class DiffEqLayer(nn.Module):\n",
        "    \"\"\"This class is a container for the computation logic in each step.\n",
        "    This layer could be used for any 'cell', also RNNs, LSTMs or GRUs.\"\"\"\n",
        "\n",
        "    def __init__(self, cell, *cell_args):\n",
        "        super().__init__()\n",
        "        self.cell = cell(*cell_args)\n",
        "\n",
        "    def forward(self, input: Tensor, state: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        inputs = input.unbind(0)\n",
        "        outputs = torch.jit.annotate(List[Tensor], [])\n",
        "        for i in range(len(inputs)):\n",
        "            out, state = self.cell(inputs[i], state)\n",
        "            outputs += [out]\n",
        "        return torch.stack(outputs), state\n",
        "\n",
        "\n",
        "class TNNCell(nn.Module):\n",
        "    \"\"\"The main TNN logic. Here, the sub-NNs are initialized as well as the constant learnable\n",
        "    thermal capacitances. The forward function houses the LPTN ODE discretized with the explicit Euler method\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.sample_time = 0.5  # in s\n",
        "        self.output_size = len(target_cols)\n",
        "        self.caps = TorchParam(torch.Tensor(self.output_size).to(device))\n",
        "        nn.init.normal_(\n",
        "            self.caps, mean=-9.2, std=0.5\n",
        "        )  # hand-picked init mean, might be application-dependent\n",
        "        n_temps = len(temperature_cols)  # number of temperatures (targets and input)\n",
        "        n_conds = int(0.5 * n_temps * (n_temps - 1))  # number of thermal conductances\n",
        "        # conductance net sub-NN\n",
        "        self.conductance_net = nn.Sequential(\n",
        "            nn.Linear(len(input_cols) + self.output_size, n_conds), nn.Sigmoid()\n",
        "        )\n",
        "        # populate adjacency matrix. It is used for indexing the conductance sub-NN output\n",
        "        self.adj_mat = np.zeros((n_temps, n_temps), dtype=int)\n",
        "        adj_idx_arr = np.ones_like(self.adj_mat)\n",
        "        triu_idx = np.triu_indices(n_temps, 1)\n",
        "        adj_idx_arr = adj_idx_arr[triu_idx].ravel()\n",
        "        self.adj_mat[triu_idx] = np.cumsum(adj_idx_arr) - 1\n",
        "        self.adj_mat += self.adj_mat.T\n",
        "        self.adj_mat = torch.from_numpy(self.adj_mat[: self.output_size, :]).type(\n",
        "            torch.int64\n",
        "        )  # crop\n",
        "        self.n_temps = n_temps\n",
        "\n",
        "        # power loss sub-NN\n",
        "        self.ploss = nn.Sequential(\n",
        "            nn.Linear(len(input_cols) + self.output_size, 16),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(16, self.output_size),\n",
        "        )\n",
        "\n",
        "        self.temp_idcs = [i for i, x in enumerate(input_cols) if x in temperature_cols]\n",
        "        self.nontemp_idcs = [\n",
        "            i\n",
        "            for i, x in enumerate(input_cols)\n",
        "            if x not in temperature_cols + [\"profile_id\"]\n",
        "        ]\n",
        "\n",
        "    def forward(self, inp: Tensor, hidden: Tensor) -> Tuple[Tensor, Tensor]:\n",
        "        prev_out = hidden\n",
        "        temps = torch.cat([prev_out, inp[:, self.temp_idcs]], dim=1)\n",
        "        sub_nn_inp = torch.cat([inp, prev_out], dim=1)\n",
        "        conducts = torch.abs(self.conductance_net(sub_nn_inp))\n",
        "        power_loss = torch.abs(self.ploss(sub_nn_inp))\n",
        "        temp_diffs = torch.sum(\n",
        "            (temps.unsqueeze(1) - prev_out.unsqueeze(-1)) * conducts[:, self.adj_mat],\n",
        "            dim=-1,\n",
        "        )\n",
        "        out = prev_out + self.sample_time * torch.exp(self.caps) * (\n",
        "            temp_diffs + power_loss\n",
        "        )\n",
        "        return prev_out, torch.clip(out, -1, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1038587d",
      "metadata": {
        "id": "1038587d"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11740783",
      "metadata": {
        "metadata": {},
        "id": "11740783"
      },
      "outputs": [],
      "source": [
        "model = torch.jit.script(DiffEqLayer(TNNCell).to(device))\n",
        "loss_func = nn.MSELoss(reduction=\"none\")\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "n_epochs = 100\n",
        "tbptt_size = 512\n",
        "\n",
        "n_batches = np.ceil(train_tensor.shape[0] / tbptt_size).astype(int)\n",
        "with tqdm(desc=\"Training\", total=n_epochs) as pbar:\n",
        "    for epoch in range(n_epochs):\n",
        "        # first state is ground truth temperature data\n",
        "        hidden = train_tensor[0, :, -len(target_cols) :]\n",
        "\n",
        "        # propagate batch-wise through data set\n",
        "        for i in range(n_batches):\n",
        "            model.zero_grad()\n",
        "            output, hidden = model(\n",
        "                train_tensor[\n",
        "                    i * tbptt_size : (i + 1) * tbptt_size, :, : len(input_cols)\n",
        "                ],\n",
        "                hidden.detach(),\n",
        "            )\n",
        "            loss = loss_func(\n",
        "                output,\n",
        "                train_tensor[\n",
        "                    i * tbptt_size : (i + 1) * tbptt_size, :, -len(target_cols) :\n",
        "                ],\n",
        "            )\n",
        "            # sample_weighting\n",
        "            loss = (\n",
        "                (\n",
        "                    loss\n",
        "                    * train_sample_weights[\n",
        "                        i * tbptt_size : (i + 1) * tbptt_size, :, None\n",
        "                    ]\n",
        "                    / train_sample_weights[\n",
        "                        i * tbptt_size : (i + 1) * tbptt_size, :\n",
        "                    ].sum()\n",
        "                )\n",
        "                .sum()\n",
        "                .mean()\n",
        "            )\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        # reduce learning rate\n",
        "        if epoch == 75:\n",
        "            for group in opt.param_groups:\n",
        "                group[\"lr\"] *= 0.5\n",
        "        pbar.update()\n",
        "        pbar.set_postfix_str(f\"loss: {loss.item():.2e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38fa8900",
      "metadata": {
        "id": "38fa8900"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f24f237",
      "metadata": {
        "metadata": {},
        "id": "4f24f237"
      },
      "outputs": [],
      "source": [
        "# model saving and loading\n",
        "mdl_path = Path.cwd() / 'data' / 'models'\n",
        "mdl_path.mkdir(exist_ok=True, parents=True)\n",
        "mdl_file_path = mdl_path / 'tnn_jit_torch.pt'\n",
        "\n",
        "model.save(mdl_file_path)  # save\n",
        "model = torch.jit.load(mdl_file_path)  # load\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "388ed64b",
      "metadata": {
        "metadata": {},
        "id": "388ed64b"
      },
      "outputs": [],
      "source": [
        "# evaluate against test set\n",
        "with torch.no_grad():\n",
        "    pred, hidden = model(\n",
        "        test_tensor[:, :, : len(input_cols)], test_tensor[0, :, -len(target_cols) :]\n",
        "    )\n",
        "    pred = pred.cpu().numpy() * 200  # denormalize"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e6d35a",
      "metadata": {
        "id": "e7e6d35a"
      },
      "source": [
        "## Visualize Performance\n",
        "We see the performance for one trial, i.e., one run of random initialized weights.\n",
        "\n",
        "Usually, running multiple trials with different random number generator seeds yields even better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85409562",
      "metadata": {
        "metadata": {},
        "id": "85409562"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(len(test_profiles), len(target_cols), figsize=(20, 10))\n",
        "for i, (pid, y_test) in enumerate(\n",
        "    data.loc[data.profile_id.isin(test_profiles), target_cols + [\"profile_id\"]].groupby(\n",
        "        \"profile_id\"\n",
        "    )\n",
        "):\n",
        "    y_test *= 200\n",
        "    profile_pred = pred[: len(y_test), i, :]\n",
        "    for j, col in enumerate(target_cols):\n",
        "        ax = axes[i, j]\n",
        "        ax.plot(\n",
        "            y_test.loc[:, col].reset_index(drop=True),\n",
        "            color=\"tab:green\",\n",
        "            label=\"Ground truth\",\n",
        "        )\n",
        "        ax.plot(profile_pred[:, j], color=\"tab:blue\", label=\"Prediction\")\n",
        "        ax.text(\n",
        "            x=0.5,\n",
        "            y=0.8,\n",
        "            s=f\"MSE: {((profile_pred[:, j] - y_test.loc[:, col])**2).sum() / len(profile_pred):.3f} K²\\nmax.abs.:{(profile_pred[:, j]-y_test.loc[:, col]).abs().max():.1f} K\",\n",
        "            transform=ax.transAxes,\n",
        "        )\n",
        "        if j == 0:\n",
        "            ax.set_ylabel(f\"Profile {pid}\\n Temp. in °C\")\n",
        "            if i == 0:\n",
        "                ax.legend()\n",
        "        if i == len(test_profiles) - 1:\n",
        "            ax.set_xlabel(f\"Iters\")\n",
        "        elif i == 0:\n",
        "            ax.set_title(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce9707f4",
      "metadata": {
        "id": "ce9707f4"
      },
      "source": [
        "The performance that is achievable by the hybridization of LPTNs with neural networks is unprecedented and not achievable by pure LPTN or pure black-box ML models.\n",
        "Note that the visualized performance stems from training a TNN from scratch once. All neural networks are initialized randomly when their training by gradient descent begins.\n",
        "This means that better performance can be easily achieved by repeating this experiment since the convergence into better local minima becomes likely."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d7797872260fffc3150fb09aa844ee2632394704ff9dbe7473c5eb66442c979a"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}